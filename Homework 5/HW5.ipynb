{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGJV4jYSHQ-P",
        "colab_type": "text"
      },
      "source": [
        "# Dependencies and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I07rI6RBILj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"drive/My Drive/\"\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oay4a7orHNtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = '/content/drive/My Drive/Colab Notebooks/'\n",
        "harry_potter_books = ['Harry Potter 1 - Sorcerer\\'s Stone.txt', 'Harry Potter 2 - Chamber of Secrets.txt', 'Harry Potter 3 - The Prisoner Of Azkaban.txt', 'Harry Potter 4 - The Goblet Of Fire.txt', 'Harry Potter 5 - Order of the Phoenix.txt', 'Harry Potter 6 - The Half Blood Prince.txt', 'Harry Potter 7 - Deathly Hollows.txt']\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_sMMLpc8hJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLWNdkNM4kuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1yrK1k2GTUw",
        "colab_type": "text"
      },
      "source": [
        "## Import PyMagnitude\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuveKqpLGagw",
        "colab_type": "code",
        "outputId": "59d692b9-007d-4c77-beef-6b94a28a9e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install pymagnitude\n",
        "from pymagnitude import *\n",
        "file_path = \"GoogleNews-vectors-negative300.magnitude\"\n",
        "vectors = Magnitude(root + file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymagnitude in /usr/local/lib/python3.6/dist-packages (0.1.120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTvu6SULWPFj",
        "colab_type": "text"
      },
      "source": [
        "## Concatenation of Magnitude Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2adS5g_MWRsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = Magnitude(root + \"GoogleNews-vectors-negative300.magnitude\")\n",
        "gv = Magnitude(root + \"glove.6B.300d.magnitude\")\n",
        "supervectors = Magnitude(w2v , gv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgDyJg5U9tmu",
        "colab_type": "text"
      },
      "source": [
        "# Write Files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0GGfnUY9y9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_file(filename, results):\n",
        "  '''\n",
        "    Input: List ['this is an', 'example']\n",
        "    Output: This overwirtes file every time, does not append\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "  results.insert(0,'******* New File ' + str(dateTimeObj) + '***********')\n",
        "  with open(filename,'w') as f:\n",
        "      for item in results:\n",
        "          f.write(str(item) + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch1sM2OBBc3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def append_to_output_file(filename, results):\n",
        "  '''\n",
        "    Input: List ['this is an', 'example']\n",
        "    Output: Write line by line\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "  results.insert(0,'******* New File ' + str(dateTimeObj) + '***********')\n",
        "  \n",
        "  ## write to output file\n",
        "  with open(filename,'a') as f:\n",
        "      results.insert(0, \"*******  Beginning of new File  ********\")\n",
        "      print(type(results))\n",
        "      for item in results:\n",
        "          f.write(str(item) + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw73ueR9DRPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_outfile(filename, results):\n",
        "  '''\n",
        "    Input: String\n",
        "    Appends to same file instead of over-writing\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "\n",
        "  with open(filename,'a') as f:\n",
        "      f.write('******* Beginning of file ' + str(dateTimeObj) +  '********\\n')\n",
        "      f.write(results + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVsCPf3OFVJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_outfile_with_modelname(filename, results, modelname):\n",
        "  '''\n",
        "    Input: String\n",
        "    Appends to same file instead of over-writing\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "\n",
        "  with open(filename,'a') as f:\n",
        "      f.write(modelname + '\\n')\n",
        "      f.write('******* Beginning of file ' + str(dateTimeObj) +  '********\\n')\n",
        "      f.write(results + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvuvlXDPEGEN",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUO6FNSbE7K1",
        "colab_type": "text"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D_PWVB9K5nJ",
        "colab_type": "text"
      },
      "source": [
        "'''\n",
        "part1.txt\n",
        "'''\n",
        "\n",
        "This file provides space to answer the questions for Part 1 of Assignment 4.\n",
        "\n",
        "Answer each question following `YOUR ANSWER HERE`, by replacing the <ANSWER>\n",
        "tag with your own answer. Make sure your answer goes **on the same line**\n",
        "as \"YOUR ANSWER HERE:\".\n",
        "\n",
        "---\n",
        "1. What is the dimensionality of these word embeddings? Provide an integer answer.\n",
        "\n",
        "YOUR ANSWER HERE: (3000000,2)\n",
        "\n",
        "2. What are the top-5 most similar words to `picnic` (not including `picnic` itself)?\n",
        "Write your answer space-separated strings, i.e. \"word1 word2 word3 word4 word5\".\n",
        "\n",
        "YOUR ANSWER HERE: picnics picnic_lunch Picnic potluck_picnic picnic_supper\n",
        "\n",
        "3. According to the word embeddings, which of these words is not like the others?\n",
        "['tissue', 'papyrus', 'manila', 'newsprint', 'parchment', 'gazette']\n",
        "Provide a single string as the answer.\n",
        "\n",
        "YOUR ANSWER HERE: tissue\n",
        "\n",
        "4. Solve the following analogy: `leg` is to `jump` as X is to `throw`.\n",
        "Provide a single string as the answer.\n",
        "\n",
        "YOUR ANSWER HERE: forearm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDdZlQrUM02H",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7-zZVIgMzYu",
        "colab_type": "code",
        "outputId": "22399c87-082f-4e4f-b926-798f69e023d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"(\" + str(len(vectors)) + \",\" + str(len(vectors[0])) + \")\")\n",
        "# for row in vectors[0:1]:\n",
        "#   print(row[0])\n",
        "#   print(row[1])\n",
        "print(len(vectors))\n",
        "print(vectors.dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000000,2)\n",
            "3000000\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwOs7JAPNklM",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFNghfEZNjOo",
        "colab_type": "code",
        "outputId": "5909bae1-be74-43a3-b65d-9c5bd8474bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"distance between cat and dog: \", vectors.distance(\"cat\", \"dog\"))\n",
        "## 0.69145405\n",
        "\n",
        "k = vectors.query(\"picnic\")\n",
        "most_sim = vectors.most_similar(k, topn = 10)\n",
        "# print(most_sim[:5])\n",
        "limit = 1\n",
        "results = []\n",
        "for word,score in most_sim:\n",
        "  if word != \"picnic\" and limit <= 5:\n",
        "    results.append(word)\n",
        "    limit += 1\n",
        "\n",
        "print(\" \".join(results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distance between cat and dog:  0.69145405\n",
            "picnics picnic_lunch Picnic potluck_picnic picnic_supper\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG5seI1pcBtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "limit = 1\n",
        "final1 = []\n",
        "final2 = []\n",
        "\n",
        "res1 = vectors.most_similar(\"picnic\", topn = 10) # Most similar by key\n",
        "\n",
        "for word,score in res1:\n",
        "  if word != \"picnic\" and limit <= 5:\n",
        "    final1.append(word)\n",
        "    limit += 1\n",
        "\n",
        "res2 = vectors.most_similar(vectors.query(\"picnic\"), topn = 10) # Most similar by vector\n",
        "print(\"res2: \", res2)\n",
        "limit = 1\n",
        "for word,score in res2:\n",
        "  if word != \"picnic\" and limit <= 5:\n",
        "    final2.append(word)\n",
        "    limit += 1\n",
        "\n",
        "print(final1 == final2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T1f5iffV6NV",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1kOFV8JV7_r",
        "colab_type": "code",
        "outputId": "f9173899-e58d-49e9-d18b-7826e1b88495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "options_list = ['tissue', 'papyrus', 'manila', 'newsprint', 'parchment', 'gazette']\n",
        "\n",
        "print(vectors.doesnt_match(options_list))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tissue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt8fm9TDbyYP",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw9LSuA9b0Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors.most_similar(positive = [\"throw\",\"leg\"], negative = [\"jump\"]) # queen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giFyvtHpv42W",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Main Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sQspRaFv6w_",
        "colab_type": "code",
        "outputId": "5cb28c99-6f60-4721-a74d-2f7ae6425c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "    vectors = Magnitude(root + 'GoogleNews-vectors-negative300.magnitude')\n",
        "    df = pd.read_csv(root + 'SimLex-999.txt', sep='\\t')[['word1', 'word2', 'SimLex999']]\n",
        "    human_scores = []\n",
        "    words_to_human_scores = []\n",
        "    vector_scores = []\n",
        "    words_to_vec_similarity = []  \n",
        "    results = []\n",
        "\n",
        "    for word1, word2, score in df.values.tolist():\n",
        "        human_scores.append(score)\n",
        "        words_to_human_scores.append((score, [word1,word2]))\n",
        "        similarity_score = vectors.similarity(word1, word2)\n",
        "        vector_scores.append(similarity_score)\n",
        "        words_to_vec_similarity.append((similarity_score, [word1,word2]))\n",
        "        # print(f'{word1}, {word2}, {score}, {similarity_score:.4f}')\n",
        "        results.append(f'{word1}, {word2}, {score}, {similarity_score:.4f}')\n",
        "\n",
        "\n",
        "    correlation, p_value = stats.kendalltau(human_scores, vector_scores)\n",
        "    print(f'Correlation = {correlation}, P Value = {p_value}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation = 0.30913428432001067, P Value = 2.6592796177777357e-48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgUNcaDHx40Q",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtgMozkx7zd",
        "colab_type": "text"
      },
      "source": [
        "1. What is the least similar 2 pairs of words based on human judgement scores and vector similarity? Do the pairs match?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oj_RhN23Opt",
        "colab_type": "code",
        "outputId": "9193630f-8d2a-423b-a86a-18361b2b85e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "words_to_human_scores = sorted(words_to_human_scores)\n",
        "print(words_to_human_scores[0])\n",
        "words_to_vec_similarity = sorted(words_to_vec_similarity)\n",
        "print(words_to_vec_similarity[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.23, ['new', 'ancient'])\n",
            "(-0.041323334, ['house', 'key'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XweN_Kc4Azh9",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFg-RtuQA2LL",
        "colab_type": "text"
      },
      "source": [
        "2. What is the most similar 2 pairs of words based on human judgement scores and vector similarity? Do the pairs match?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf2MfkFnA2iA",
        "colab_type": "code",
        "outputId": "6dae6c7a-6edb-4e38-da83-defd83b5f781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(words_to_human_scores[-1])\n",
        "print(words_to_vec_similarity[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9.8, ['vanish', 'disappear'])\n",
            "(0.9674536, ['south', 'north'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbobqA218mkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## write files\n",
        "    results.insert(0,'word1 word2 score similairtyScore')\n",
        "    write_file(\"vec_sims.txt\", results)\n",
        "    write_file(\"human_scores.txt\", human_scores)\n",
        "    write_file(\"vector_scores.txt\", vector_scores)\n",
        "    write_file(\"words_to_human_scores.txt\", words_to_human_scores)\n",
        "    write_file(\"words_to_vec_similarity.txt\", words_to_vec_similarity)\n",
        "    write_outfile(\"correlation_results.txt\", f'Correlation = {correlation}, P Value = {p_value}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRcD2kciBJOa",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Aa103RBQs-",
        "colab_type": "text"
      },
      "source": [
        "3. Provide correlation scores and p values for the following models on eniac in /home1/c/cis530/hw5_2020/vectors/:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVBcyVXRBV_O",
        "colab_type": "text"
      },
      "source": [
        "### models = ['glove.6B.50d.magnitude', 'glove.6B.100d.magnitude', 'glove.6B.200d.magnitude', 'glove.6B.300d.magnitude', 'glove.840B.300d.magnitude']\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjhU602oCAW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8ad2f6fc-97d1-4c1e-dcd6-348543531363"
      },
      "source": [
        "    models = ['glove.6B.50d.magnitude', 'glove.6B.100d.magnitude', 'glove.6B.200d.magnitude', 'glove.6B.300d.magnitude', 'glove.840B.300d.magnitude']\n",
        "    for model in models:\n",
        "      vectors = Magnitude(root + model)\n",
        "      df = pd.read_csv(root + 'SimLex-999.txt', sep='\\t')[['word1', 'word2', 'SimLex999']]\n",
        "      human_scores = []\n",
        "      words_to_human_scores = []\n",
        "      vector_scores = []\n",
        "      words_to_vec_similarity = []  \n",
        "      results = []\n",
        "\n",
        "      for word1, word2, score in df.values.tolist():\n",
        "          human_scores.append(score)\n",
        "          words_to_human_scores.append((score, [word1,word2]))\n",
        "          similarity_score = vectors.similarity(word1, word2)\n",
        "          vector_scores.append(similarity_score)\n",
        "          words_to_vec_similarity.append((similarity_score, [word1,word2]))\n",
        "          # print(f'{word1}, {word2}, {score}, {similarity_score:.4f}')\n",
        "          results.append(f'{word1}, {word2}, {score}, {similarity_score:.4f}')\n",
        "\n",
        "\n",
        "      correlation, p_value = stats.kendalltau(human_scores, vector_scores)\n",
        "      print(f'Correlation = {correlation}, P Value = {p_value}')\n",
        "      write_outfile_with_modelname(\"correlation_results.txt\", f'Correlation = {correlation}, P Value = {p_value}', model)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation = 0.18100126067449063, P Value = 1.2242211264976945e-17\n",
            "Correlation = 0.20506409092608713, P Value = 3.4122866339517884e-22\n",
            "Correlation = 0.23670323199262908, P Value = 4.9936324557834e-29\n",
            "Correlation = 0.25894302181101986, P Value = 2.080389068003349e-34\n",
            "Correlation = 0.2860664813618063, P Value = 1.2933356133610945e-41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGP6HsrBBfcI",
        "colab_type": "text"
      },
      "source": [
        "### How do those value compare to each other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39V0AfwGpsh",
        "colab_type": "text"
      },
      "source": [
        "The more dimensions to the model, the better the correlation.  P-values show that each of these correlations are significant."
      ]
    }
  ]
}