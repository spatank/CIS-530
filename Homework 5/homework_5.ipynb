{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "homework_5.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/CIS-530/blob/master/Homework%205/homework_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS80Ll4dvIcX",
        "colab_type": "code",
        "outputId": "2a5cb18d-8d04-42ae-8c3e-3d333c4f470e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install pymagnitude"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymagnitude in /usr/local/lib/python3.6/dist-packages (0.1.120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8WGugLYvUjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pymagnitude import *\n",
        "from itertools import combinations\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.cluster import KMeans\n",
        "import random\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6_3yAPlWgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0881a11-059c-4876-d762-fb8a04eaf5cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# to view contents, run following line\n",
        "# !ls drive/My\\ Drive/CIS-530/Homework\\ 5/Data"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvKJrWiuPuZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_input_file(file_path):\n",
        "    \"\"\"\n",
        "    Loads the input file to two dictionaries\n",
        "    :param file_path: path to an input file\n",
        "    :return: 2 dictionaries:\n",
        "    1. Dictionary, where key is a target word and value is a list of paraphrases\n",
        "    2. Dictionary, where key is a target word and value is a number of clusters\n",
        "    \"\"\"\n",
        "    word_to_paraphrases_dict = {}\n",
        "    word_to_k_dict = {}\n",
        "\n",
        "    with open(file_path, 'r') as fin:\n",
        "        for line in fin:\n",
        "            target_word, k, paraphrases = line.split(' :: ')\n",
        "            word_to_k_dict[target_word] = int(k)\n",
        "            word_to_paraphrases_dict[target_word] = paraphrases.split()\n",
        "\n",
        "    return word_to_paraphrases_dict, word_to_k_dict\n",
        "\n",
        "\n",
        "def load_output_file(file_path):\n",
        "    \"\"\"\n",
        "    :param file_path: path to an output file\n",
        "    :return: A dictionary, where key is a target word and value is a list of list of paraphrases\n",
        "    \"\"\"\n",
        "    clusterings = {}\n",
        "\n",
        "    with open(file_path, 'r') as fin:\n",
        "        for line in fin:\n",
        "            target_word, _, paraphrases_in_cluster = line.strip().split(' :: ')\n",
        "            paraphrases_list = paraphrases_in_cluster.strip().split()\n",
        "            if target_word not in clusterings:\n",
        "                clusterings[target_word] = []\n",
        "            clusterings[target_word].append(paraphrases_list)\n",
        "\n",
        "    return clusterings\n",
        "\n",
        "\n",
        "def write_to_output_file(file_path, clusterings):\n",
        "    \"\"\"\n",
        "    Writes the result of clusterings into an output file\n",
        "    :param file_path: path to an output file\n",
        "    :param clusterings:  A dictionary, where key is a target word and value is a list of list of paraphrases\n",
        "    :return: N/A\n",
        "    \"\"\"\n",
        "    with open(file_path, 'w') as fout:\n",
        "        for target_word, clustering in clusterings.items():\n",
        "            for i, cluster in enumerate(clustering):\n",
        "                fout.write(f'{target_word} :: {i + 1} :: {\" \".join(cluster)}\\n')\n",
        "        fout.close()\n",
        "\n",
        "\n",
        "def get_paired_f_score(gold_clustering, predicted_clustering):\n",
        "    \"\"\"\n",
        "    :param gold_clustering: gold list of list of paraphrases\n",
        "    :param predicted_clustering: predicted list of list of paraphrases\n",
        "    :return: Paired F-Score\n",
        "    \"\"\"\n",
        "    gold_pairs = set()\n",
        "    for gold_cluster in gold_clustering:\n",
        "        for pair in combinations(gold_cluster, 2):\n",
        "            gold_pairs.add(tuple(sorted(pair)))\n",
        "\n",
        "    predicted_pairs = set()\n",
        "    for predicted_cluster in predicted_clustering:\n",
        "        for pair in combinations(predicted_cluster, 2):\n",
        "            predicted_pairs.add(tuple(sorted(pair)))\n",
        "\n",
        "    overlapping_pairs = gold_pairs & predicted_pairs\n",
        "\n",
        "    precision = 1. if len(predicted_pairs) == 0 else float(len(overlapping_pairs)) / len(predicted_pairs)\n",
        "    recall = 1. if len(gold_pairs) == 0 else float(len(overlapping_pairs)) / len(gold_pairs)\n",
        "    paired_f_score = 0. if precision + recall == 0 else 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    return paired_f_score\n",
        "\n",
        "\n",
        "def evaluate_clusterings(gold_clusterings, predicted_clusterings):\n",
        "    \"\"\"\n",
        "    Displays evaluation scores between gold and predicted clusterings\n",
        "    :param gold_clusterings: dictionary where key is a target word and value is a list of list of paraphrases\n",
        "    :param predicted_clusterings: dictionary where key is a target word and value is a list of list of paraphrases\n",
        "    :return: N/A\n",
        "    \"\"\"\n",
        "    target_words = set(gold_clusterings.keys()) & set(predicted_clusterings.keys())\n",
        "\n",
        "    if len(target_words) == 0:\n",
        "        print('No overlapping target words in ground-truth and predicted files')\n",
        "        return None\n",
        "\n",
        "    paired_f_scores = np.zeros((len(target_words)))\n",
        "    ks = np.zeros((len(target_words)))\n",
        "\n",
        "    table = PrettyTable(['Target', 'k', 'Paired F-Score'])\n",
        "    for i, target_word in enumerate(target_words):\n",
        "        paired_f_score = get_paired_f_score(gold_clusterings[target_word], predicted_clusterings[target_word])\n",
        "        k = len(gold_clusterings[target_word])\n",
        "        paired_f_scores[i] = paired_f_score\n",
        "        ks[i] = k\n",
        "        table.add_row([target_word, k, f'{paired_f_score:0.4f}'])\n",
        "\n",
        "    average_f_score = np.average(paired_f_scores, weights=ks)\n",
        "    print(table)\n",
        "    print(f'=> Average Paired F-Score:  {average_f_score:.4f}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO8PtCMkzP73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(123)\n",
        "\n",
        "# TASK 3.1\n",
        "def cluster_random(word_to_paraphrases_dict, word_to_k_dict):\n",
        "    \"\"\"\n",
        "    Clusters paraphrases randomly\n",
        "    :param word_to_paraphrases_dict: dictionary, where key is a target word and value is a list of paraphrases\n",
        "    :param word_to_k_dict: dictionary, where key is a target word and value is a number of clusters\n",
        "    :return: dictionary, where key is a target word and value is a list of list of paraphrases,\n",
        "    where each list corresponds to a cluster\n",
        "    \"\"\"\n",
        "    clusterings = {}\n",
        "\n",
        "    for target_word in word_to_paraphrases_dict.keys():\n",
        "        paraphrase_list = word_to_paraphrases_dict[target_word]\n",
        "        clusters = []\n",
        "        k = word_to_k_dict[target_word] # number of clusters for target word\n",
        "        chosen_paraphrases = set() # keep track of any paraphrases that may not be randomly chosen\n",
        "        for cluster in range(k): \n",
        "          # each word must have a cluster, each cluster must have a word\n",
        "          cluster_list = random.choices(paraphrase_list, k = int(np.round(len(paraphrase_list)/k)))\n",
        "          chosen_paraphrases.update(cluster_list)\n",
        "          clusters.append(cluster_list)\n",
        "        for paraphrase in paraphrase_list:\n",
        "          if paraphrase not in chosen_paraphrases:\n",
        "            # choose a random cluster list and append unassigned word to it\n",
        "            random.choice(clusters).append(paraphrase) \n",
        "        clusterings[target_word] = clusters\n",
        "\n",
        "    return clusterings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QcL2uySlmGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "2fa53c51-d93f-426c-d2d8-d8df64f3bed3"
      },
      "source": [
        "input_filepath = 'drive/My Drive/CIS-530/Homework 5/Data/data/dev_input.txt'\n",
        "output_filepath = 'drive/My Drive/CIS-530/Homework 5/Data/data/dev_output.txt'\n",
        "word_to_paraphrases_dict, word_to_k_dict = load_input_file(input_filepath)\n",
        "gold_clusterings = load_output_file(output_filepath)\n",
        "predicted_clusterings = cluster_random(word_to_paraphrases_dict, word_to_k_dict)\n",
        "evaluate_clusterings(gold_clusterings, predicted_clusterings)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+----+----------------+\n",
            "|     Target     | k  | Paired F-Score |\n",
            "+----------------+----+----------------+\n",
            "|     wash.v     | 13 |     0.1697     |\n",
            "|    watch.v     | 5  |     0.2393     |\n",
            "|    expect.v    | 6  |     0.2927     |\n",
            "|    paper.n     | 7  |     0.3158     |\n",
            "|     miss.v     | 8  |     0.2316     |\n",
            "|     eat.v      | 6  |     0.2922     |\n",
            "|  atmosphere.n  | 6  |     0.2500     |\n",
            "|     note.v     | 3  |     0.5957     |\n",
            "|     use.v      | 6  |     0.3747     |\n",
            "|   judgment.n   | 7  |     0.1887     |\n",
            "|   express.v    | 7  |     0.2300     |\n",
            "|   operate.v    | 7  |     0.2544     |\n",
            "|    begin.v     | 8  |     0.2132     |\n",
            "|   produce.v    | 7  |     0.2305     |\n",
            "|    smell.v     | 4  |     0.5169     |\n",
            "|     mean.v     | 6  |     0.2431     |\n",
            "|   interest.n   | 5  |     0.2340     |\n",
            "|    party.n     | 5  |     0.2421     |\n",
            "|   suspend.v    | 6  |     0.2034     |\n",
            "|    source.n    | 9  |     0.1728     |\n",
            "|  difference.n  | 5  |     0.3724     |\n",
            "|     bank.n     | 9  |     0.2326     |\n",
            "|     plan.n     | 3  |     0.4989     |\n",
            "|    simple.a    | 5  |     0.1333     |\n",
            "|     hear.v     | 5  |     0.2740     |\n",
            "| performance.n  | 5  |     0.3240     |\n",
            "|     play.v     | 34 |     0.0543     |\n",
            "|  different.a   | 1  |     1.0000     |\n",
            "|    write.v     | 9  |     0.2313     |\n",
            "|     talk.v     | 6  |     0.3318     |\n",
            "| organization.n | 7  |     0.2191     |\n",
            "|    degree.n    | 7  |     0.2956     |\n",
            "|   provide.v    | 7  |     0.3317     |\n",
            "|    climb.v     | 6  |     0.2069     |\n",
            "|   shelter.n    | 5  |     0.3463     |\n",
            "|   receive.v    | 13 |     0.0603     |\n",
            "|     rule.v     | 7  |     0.1839     |\n",
            "|     win.v      | 4  |     0.2885     |\n",
            "|    treat.v     | 8  |     0.2271     |\n",
            "|    image.n     | 9  |     0.1646     |\n",
            "+----------------+----+----------------+\n",
            "=> Average Paired F-Score:  0.2261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ81Z6GzxzhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_to_paraphrases_dict, word_to_k_dict = load_input_file('drive/My Drive/CIS-530/Homework 5/Data/data/test_input.txt')\n",
        "# predicted_clusterings = cluster_random(word_to_paraphrases_dict, word_to_k_dict)\n",
        "# write_to_output_file('drive/My Drive/CIS-530/Homework 5/test_output_random.txt', predicted_clusterings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_C0noixINDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_PPMI_matrix(term_context_matrix):\n",
        "  '''Given a term context matrix, output a PPMI matrix.\n",
        "  See section 15.1 in the textbook.\n",
        "\n",
        "  Hint: Use numpy matrix and vector operations to speed up implementation.\n",
        "  \n",
        "  Input:\n",
        "    term_context_matrix: A nxn numpy array, where n is\n",
        "        the numer of tokens in the vocab.\n",
        "  \n",
        "  Returns: A nxn numpy matrix, where A_ij is equal to the\n",
        "     point-wise mutual information between the ith word\n",
        "     and the jth word in the term_context_matrix.\n",
        "  '''       \n",
        "  target_counts = np.sum(term_context_matrix, axis = 1)\n",
        "  context_counts = np.sum(term_context_matrix, axis = 0)\n",
        "  total = np.sum(term_context_matrix) # matrix sum\n",
        "  PPMI_matrix = np.divide(np.multiply(term_context_matrix,total),np.multiply(target_counts,context_counts.T))\n",
        "  PPMI_matrix = np.maximum(0, np.log2(PPMI_matrix+1e-6))\n",
        "  \n",
        "  return PPMI_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adg1ux23lIU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK 3.2\n",
        "def cluster_with_sparse_representation(word_to_paraphrases_dict, word_to_k_dict):\n",
        "    \"\"\"\n",
        "    Clusters paraphrases using sparse vector representation\n",
        "    :param word_to_paraphrases_dict: dictionary, where key is a target word and value is a list of paraphrases\n",
        "    :param word_to_k_dict: dictionary, where key is a target word and value is a number of clusters\n",
        "    :return: dictionary, where key is a target word and value is a list of list of paraphrases,\n",
        "    where each list corresponds to a cluster\n",
        "    \"\"\"\n",
        "    # Note: any vector representation should be in the same directory as this file\n",
        "    vectors_root_path = 'drive/My Drive/CIS-530/Homework 5/Data/vectors/'\n",
        "    vectors_path = 'coocvec-500mostfreq-window-3.filter.magnitude'\n",
        "    vectors = Magnitude(vectors_root_path + vectors_path)\n",
        "    clusterings = {}\n",
        "\n",
        "    for target_word in word_to_paraphrases_dict.keys():\n",
        "        paraphrase_list = word_to_paraphrases_dict[target_word]\n",
        "        clusters = []\n",
        "        k = word_to_k_dict[target_word]\n",
        "        chosen_paraphrases = set() # keep track of any paraphrases that may not be chosen\n",
        "        X = np.zeros((len(paraphrase_list), 500))\n",
        "        # build data matrix\n",
        "        for idx, paraphrase in enumerate(paraphrase_list):\n",
        "          X[idx,:] = vectors.query(paraphrase)\n",
        "        # X = create_PPMI_matrix(X)\n",
        "        kmeans = KMeans(n_clusters = k).fit(X)\n",
        "        for cluster in range(k):\n",
        "          cluster_list = [paraphrase_list[idx] \n",
        "                          for idx, label in enumerate(kmeans.labels_) \n",
        "                          if label == cluster]\n",
        "          if len(cluster_list) == 0:\n",
        "            print('Empty cluster\\n')\n",
        "          chosen_paraphrases.update(cluster_list)\n",
        "          clusters.append(cluster_list)\n",
        "        for paraphrase in paraphrase_list:\n",
        "          if paraphrase not in chosen_paraphrases:\n",
        "            # choose a random cluster list and append unassigned word to it\n",
        "            random.choice(clusters).append(paraphrase) \n",
        "        clusterings[target_word] = clusters\n",
        "\n",
        "    return clusterings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TxsDraa0Vcd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "577322e5-dbd6-47e0-b93a-4498bd875185"
      },
      "source": [
        "input_filepath = 'drive/My Drive/CIS-530/Homework 5/Data/data/dev_input.txt'\n",
        "output_filepath = 'drive/My Drive/CIS-530/Homework 5/Data/data/dev_output.txt'\n",
        "word_to_paraphrases_dict, word_to_k_dict = load_input_file(input_filepath)\n",
        "gold_clusterings = load_output_file(output_filepath)\n",
        "predicted_clusterings = cluster_with_sparse_representation(word_to_paraphrases_dict, word_to_k_dict)\n",
        "evaluate_clusterings(gold_clusterings, predicted_clusterings)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+----+----------------+\n",
            "|     Target     | k  | Paired F-Score |\n",
            "+----------------+----+----------------+\n",
            "|     wash.v     | 13 |     0.1685     |\n",
            "|    watch.v     | 5  |     0.3796     |\n",
            "|    expect.v    | 6  |     0.2767     |\n",
            "|    paper.n     | 7  |     0.3085     |\n",
            "|     miss.v     | 8  |     0.2157     |\n",
            "|     eat.v      | 6  |     0.2543     |\n",
            "|  atmosphere.n  | 6  |     0.3184     |\n",
            "|     note.v     | 3  |     0.4878     |\n",
            "|     use.v      | 6  |     0.4096     |\n",
            "|   judgment.n   | 7  |     0.2212     |\n",
            "|   express.v    | 7  |     0.2329     |\n",
            "|   operate.v    | 7  |     0.2144     |\n",
            "|    begin.v     | 8  |     0.3377     |\n",
            "|   produce.v    | 7  |     0.3159     |\n",
            "|    smell.v     | 4  |     0.2500     |\n",
            "|     mean.v     | 6  |     0.3391     |\n",
            "|   interest.n   | 5  |     0.2586     |\n",
            "|    party.n     | 5  |     0.2664     |\n",
            "|   suspend.v    | 6  |     0.2090     |\n",
            "|    source.n    | 9  |     0.2341     |\n",
            "|  difference.n  | 5  |     0.3354     |\n",
            "|     bank.n     | 9  |     0.3291     |\n",
            "|     plan.n     | 3  |     0.5553     |\n",
            "|    simple.a    | 5  |     0.3704     |\n",
            "|     hear.v     | 5  |     0.3855     |\n",
            "| performance.n  | 5  |     0.2478     |\n",
            "|     play.v     | 34 |     0.0941     |\n",
            "|  different.a   | 1  |     1.0000     |\n",
            "|    write.v     | 9  |     0.1926     |\n",
            "|     talk.v     | 6  |     0.3375     |\n",
            "| organization.n | 7  |     0.2467     |\n",
            "|    degree.n    | 7  |     0.2451     |\n",
            "|   provide.v    | 7  |     0.3110     |\n",
            "|    climb.v     | 6  |     0.2178     |\n",
            "|   shelter.n    | 5  |     0.3588     |\n",
            "|   receive.v    | 13 |     0.1739     |\n",
            "|     rule.v     | 7  |     0.2598     |\n",
            "|     win.v      | 4  |     0.3291     |\n",
            "|    treat.v     | 8  |     0.2388     |\n",
            "|    image.n     | 9  |     0.1466     |\n",
            "+----------------+----+----------------+\n",
            "=> Average Paired F-Score:  0.2526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7tFR-iUHjjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_paraphrases_dict, word_to_k_dict = load_input_file('drive/My Drive/CIS-530/Homework 5/Data/data/test_input.txt')\n",
        "predicted_clusterings = cluster_with_sparse_representation(word_to_paraphrases_dict, word_to_k_dict)\n",
        "write_to_output_file('drive/My Drive/CIS-530/Homework 5/test_output_sparse.txt', predicted_clusterings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwZ0aHcjlLO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK 3.3\n",
        "def cluster_with_dense_representation(word_to_paraphrases_dict, word_to_k_dict):\n",
        "    \"\"\"\n",
        "    Clusters paraphrases using dense vector representation\n",
        "    :param word_to_paraphrases_dict: dictionary, where key is a target word and value is a list of paraphrases\n",
        "    :param word_to_k_dict: dictionary, where key is a target word and value is a number of clusters\n",
        "    :return: dictionary, where key is a target word and value is a list of list of paraphrases,\n",
        "    where each list corresponds to a cluster\n",
        "    \"\"\"\n",
        "    # Note: any vector representation should be in the same directory as this file\n",
        "    vectors = Magnitude(\"GoogleNews-vectors-negative300.filter.magnitude\")\n",
        "    clusterings = {}\n",
        "\n",
        "    for target_word in word_to_paraphrases_dict.keys():\n",
        "        paraphrase_list = word_to_paraphrases_dict[target_word]\n",
        "        k = word_to_k_dict[target_word]\n",
        "        # TODO: Implement\n",
        "        clusterings[target_word] = None\n",
        "\n",
        "    return clusterings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ZAYAt9lN-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK 3.4\n",
        "def cluster_with_no_k(word_to_paraphrases_dict):\n",
        "    \"\"\"\n",
        "    Clusters paraphrases using any vector representation\n",
        "    :param word_to_paraphrases_dict: dictionary, where key is a target word and value is a list of paraphrases\n",
        "    :return: dictionary, where key is a target word and value is a list of list of paraphrases,\n",
        "    where each list corresponds to a cluster\n",
        "    \"\"\"\n",
        "    # Note: any vector representation should be in the same directory as this file\n",
        "    vectors = Magnitude(\"GoogleNews-vectors-negative300.filter.magnitude\")\n",
        "    clusterings = {}\n",
        "\n",
        "    for target_word in word_to_paraphrases_dict.keys():\n",
        "        paraphrase_list = word_to_paraphrases_dict[target_word]\n",
        "        # TODO: Implement\n",
        "        clusterings[target_word] = None\n",
        "\n",
        "    return clusterings"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}