{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw6_skeleton_RIF_edit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatank/CIS-530/blob/master/Homework%206/hw6_skeleton_RIF_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3g9-BaUNri6",
        "colab_type": "text"
      },
      "source": [
        "# Download and unzip files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CNS4OZXxMZ-A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3933a1d-4a5d-430a-96c0-dc98b6909cbe"
      },
      "source": [
        "#Download and unzip files\n",
        "!pip3 install scikit-learn\n",
        "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_test.txt\n",
        "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_val.zip\n",
        "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_train.zip\n",
        "!sudo apt-get install unzip\n",
        "!unzip cities_val.zip \n",
        "!unzip cities_train.zip \n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torch torchvision\n",
        "  \n",
        "import torch\n",
        "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "--2020-02-22 21:15:51--  http://computational-linguistics-class.org/homework/nn-lms/cities_test.txt\n",
            "Resolving computational-linguistics-class.org (computational-linguistics-class.org)... 185.199.110.153\n",
            "Connecting to computational-linguistics-class.org (computational-linguistics-class.org)|185.199.110.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10973 (11K) [text/plain]\n",
            "Saving to: ‘cities_test.txt’\n",
            "\n",
            "cities_test.txt     100%[===================>]  10.72K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-22 21:15:51 (394 MB/s) - ‘cities_test.txt’ saved [10973/10973]\n",
            "\n",
            "--2020-02-22 21:15:53--  http://computational-linguistics-class.org/homework/nn-lms/cities_val.zip\n",
            "Resolving computational-linguistics-class.org (computational-linguistics-class.org)... 185.199.110.153\n",
            "Connecting to computational-linguistics-class.org (computational-linguistics-class.org)|185.199.110.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7558 (7.4K) [application/zip]\n",
            "Saving to: ‘cities_val.zip’\n",
            "\n",
            "cities_val.zip      100%[===================>]   7.38K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-22 21:15:53 (1.29 GB/s) - ‘cities_val.zip’ saved [7558/7558]\n",
            "\n",
            "--2020-02-22 21:15:56--  http://computational-linguistics-class.org/homework/nn-lms/cities_train.zip\n",
            "Resolving computational-linguistics-class.org (computational-linguistics-class.org)... 185.199.110.153\n",
            "Connecting to computational-linguistics-class.org (computational-linguistics-class.org)|185.199.110.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159676 (156K) [application/zip]\n",
            "Saving to: ‘cities_train.zip’\n",
            "\n",
            "cities_train.zip    100%[===================>] 155.93K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2020-02-22 21:15:56 (32.4 MB/s) - ‘cities_train.zip’ saved [159676/159676]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Archive:  cities_val.zip\n",
            "   creating: val/\n",
            "  inflating: val/af.txt              \n",
            "  inflating: val/cn.txt              \n",
            "  inflating: val/de.txt              \n",
            "  inflating: val/fi.txt              \n",
            "  inflating: val/fr.txt              \n",
            "  inflating: val/ir.txt              \n",
            "  inflating: val/za.txt              \n",
            "  inflating: val/pk.txt              \n",
            "  inflating: val/in.txt              \n",
            "Archive:  cities_train.zip\n",
            "   creating: train/\n",
            "  inflating: train/af.txt            \n",
            "  inflating: train/de.txt            \n",
            "  inflating: train/fi.txt            \n",
            "  inflating: train/fr.txt            \n",
            "  inflating: train/in.txt            \n",
            "  inflating: train/ir.txt            \n",
            "  inflating: train/cn.txt            \n",
            "  inflating: train/za.txt            \n",
            "  inflating: train/pk.txt            \n",
            "Collecting torch==1.0.1\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl (614.8MB)\n",
            "\u001b[K     |████████████████████████████████| 614.8MB 29kB/s \n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-1.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q32qfGbtPOIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dcea361d-efb3-4e49-bc17-caba7144f801"
      },
      "source": [
        "print(print(torch.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUD8EE5fNvhR",
        "colab_type": "text"
      },
      "source": [
        "# Verify file download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qIJxbqMDNTTl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "7b255bdb-df97-4944-b7b9-115330eb5aba"
      },
      "source": [
        "#Verfiy file download\n",
        "!head train/af.txt\n",
        "!printf \"\\n\"\n",
        "!head val/af.txt\n",
        "!printf \"\\n\"\n",
        "!head cities_test.txt\n",
        "!printf \"\\n\"\n",
        "#Verify CUDA acceleration should print cuda:0\n",
        "print(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "garavshakh\n",
            "kalishli\n",
            "sarban kelay\n",
            "dahan-e surunah\n",
            "jahannum\n",
            "morafeno\n",
            "iskatel\n",
            "zeri-chinar\n",
            "taftebole\n",
            "dzhafarabat\n",
            "\n",
            "sikhtopa\n",
            "laferronay\n",
            "cham ghafur\n",
            "souk tafetecht\n",
            "panqash\n",
            "siah sar bala\n",
            "barah khan kili\n",
            "vetob\n",
            "kacari\n",
            "kolga'i-i-bala\n",
            "\n",
            "imam bakhsh amar\n",
            "firoz laghari\n",
            "glufishevo\n",
            "qal`eh-ye ghazanfarkhani\n",
            "nikolinalevada\n",
            "kolkko\n",
            "mbrostar i fierit\n",
            "kharabanan-e sofla\n",
            "stein bei nurnberg\n",
            "jahangir bara\n",
            "\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTzoM1VUObhb",
        "colab_type": "text"
      },
      "source": [
        "# Paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h12cVa20OYdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = '/content/gdrive/Shared drives/cis530_hw6/'\n",
        "vectors_root = '/content/gdrive/Shared drives/vectors/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgiZ0xd4NybT",
        "colab_type": "text"
      },
      "source": [
        "# Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1eKT4SoNP3lH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "48b27159-162c-42e6-9500-40793261d0d1"
      },
      "source": [
        "# Mount your google drive. \n",
        "# Use this to save your PyTorch model for submission\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/Shared drives/cis530_hw6/'\n",
        "!ls\n",
        "#!mkdir /content/gdrive/My\\ Drive/cis530_hw6\n",
        "#Test drive access. \n",
        "#You should have a test.txt under a new folder cis530_hw6 in your Google drive\n",
        "with open('/content/gdrive/Shared drives/cis530_hw6/test.txt', 'w') as f:\n",
        "  f.write('This is a test!')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/Shared drives/cis530_hw6\n",
            "data\t\t    hw6_skeleton_RIF_edit.ipynb  skeleton  text_file.txt  val\n",
            "hw6_skeleton.ipynb  hw6_SP_edit.ipynb\t\t test.txt  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuvYM64PujGV",
        "colab_type": "text"
      },
      "source": [
        "# Baby names tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wV-7YdDulP8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b588cf3c-9388-4de7-c8b4-8182fcd1b48f"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "print(\"this is findFiles: \", findFiles(root + 'data/names/*.txt'))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8', errors='ignore').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles(root + 'data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is findFiles:  ['/content/gdrive/Shared drives/cis530_hw6/data/names/Arabic.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Chinese.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Irish.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Czech.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/German.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Dutch.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/English.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Italian.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/French.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Greek.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Japanese.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Scottish.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Vietnamese.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Portuguese.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Spanish.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Korean.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Polish.txt', '/content/gdrive/Shared drives/cis530_hw6/data/names/Russian.txt']\n",
            "Slusarski\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0j8-gdwvy8r",
        "colab_type": "text"
      },
      "source": [
        "## test category lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg9Pu6Nvuwcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a847585-e70e-4dfc-d565-37b97015f3bd"
      },
      "source": [
        "print(category_lines['Italian'][:5])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBsuzQBc7O6i",
        "colab_type": "text"
      },
      "source": [
        "# Write output files (all methods)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aEbjdzc7VC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLKFEVdv7Vu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_file(filename, results):\n",
        "  '''\n",
        "    Input: List ['this is an', 'example']\n",
        "    Output: This overwirtes file every time, does not append\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "  results.insert(0,'******* New File ' + str(dateTimeObj) + '***********')\n",
        "  with open(filename,'w') as f:\n",
        "      for item in results:\n",
        "          f.write(str(item) + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxGzsMc7bsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def append_to_output_file(filename, results):\n",
        "  '''\n",
        "    Input: List ['this is an', 'example']\n",
        "    Output: Keeps appending to same file (does NOT overwrite)\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "  results.insert(0,'******* New File ' + str(dateTimeObj) + '***********')\n",
        "  \n",
        "  ## write to output file\n",
        "  with open(filename,'a') as f:\n",
        "      results.insert(0, \"*******  Beginning of new File  ********\")\n",
        "      print(type(results))\n",
        "      for item in results:\n",
        "          f.write(str(item) + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb7Sdn1_7baI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_outfile(filename, results):\n",
        "  '''\n",
        "    Input: String\n",
        "    Output: Keeps appending to same file (does NOT overwrite)\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "\n",
        "  with open(filename,'a') as f:\n",
        "      f.write('******* Beginning of file ' + str(dateTimeObj) +  '********\\n')\n",
        "      f.write(results + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4C-d7oX7bMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ADDED\n",
        "def write_outfile_with_modelname(filename, results, modelname):\n",
        "  '''\n",
        "    Input: String, modelname to be printed with results\n",
        "    Output: Keeps appending to same file (does NOT overwrite)\n",
        "  '''\n",
        "  dateTimeObj = datetime.now()\n",
        "\n",
        "  with open(filename,'a') as f:\n",
        "      f.write(modelname + '\\n')\n",
        "      f.write('******* Beginning of file ' + str(dateTimeObj) +  '********\\n')\n",
        "      f.write(results + '\\n')\n",
        "\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rOYmPqzRffT",
        "colab_type": "text"
      },
      "source": [
        "# main_classify.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kwB5RzvfOGr_",
        "colab": {}
      },
      "source": [
        "#main_classify.py\n",
        "import codecs\n",
        "import math\n",
        "import random\n",
        "import string\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "'''\n",
        "Don't change these constants for the classification task.\n",
        "You may use different copies for the sentence generation model.\n",
        "'''\n",
        "languages = [\"af\", \"cn\", \"de\", \"fi\", \"fr\", \"in\", \"ir\", \"pk\", \"za\"]\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "\n",
        "'''\n",
        "Returns the words of the language specified by reading it from the data folder\n",
        "Returns the validation data if train is false and the train data otherwise.\n",
        "Return: A nx1 array containing the words of the specified language\n",
        "'''\n",
        "def getWords(baseDir, lang, train = True):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Returns a label corresponding to the language\n",
        "For example it returns an array of 0s for af\n",
        "Return: A nx1 array as integers containing index of the specified language in the \"languages\" array\n",
        "'''\n",
        "def getLabels(lang, length):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Returns all the laguages and labels after reading it from the file\n",
        "Returns the validation data if train is false and the train data otherwise.\n",
        "You may assume that the files exist in baseDir and have the same names.\n",
        "Return: X, y where X is nx1 and y is nx1\n",
        "'''\n",
        "def readData(baseDir, train=True):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Convert a line/word to a pytorch tensor of numbers\n",
        "Refer the tutorial in the spec\n",
        "Return: A tensor corresponding to the given line\n",
        "'''\n",
        "def line_to_tensor(line):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Returns the category/class of the output from the neural network\n",
        "Input: Output of the neural networks (class probabilities)\n",
        "Return: A tuple with (language, language_index)\n",
        "        language: \"af\", \"cn\", etc.\n",
        "        language_index: 0, 1, etc.\n",
        "'''\n",
        "def category_from_output(output):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Get a random input output pair to be used for training \n",
        "Refer the tutorial in the spec\n",
        "'''\n",
        "def random_training_pair(X, y):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Input: trained model, a list of words, a list of class labels as integers\n",
        "Output: a list of class labels as integers\n",
        "'''\n",
        "def predict(model, X, y):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Input: trained model, a list of words, a list of class labels as integers\n",
        "Output: The accuracy of the given model on the given input X and target y\n",
        "'''\n",
        "def calculateAccuracy(model, X, y):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Train the model for one epoch/one training word.\n",
        "Ensure that it runs within 3 seconds.\n",
        "Input: X and y are lists of words as strings and classes as integers respectively\n",
        "Returns: You may return anything\n",
        "'''\n",
        "def trainOneEpoch(model, criterion, optimizer, X, y):\n",
        "    pass\n",
        "\n",
        "'''\n",
        "Use this to train and save your classification model. \n",
        "Save your model with the filename \"model_classify\"\n",
        "'''\n",
        "def run():\n",
        "    pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfg87twhRlOF",
        "colab_type": "text"
      },
      "source": [
        "# models.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NbOusBLKPsrx",
        "colab": {}
      },
      "source": [
        "#models.py\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "'''\n",
        "Please add default values for all the parameters of __init__.\n",
        "'''\n",
        "class CharRNNClassify(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        pass\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        pass\n",
        "\n",
        "    def init_hidden(self):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}